Today, we have to deal with new technologies such as the internet, GPS or satellites platform, which provide us numerous and large samples of data. The data growth in the last decades implies a demand for not only a better collection and storage of data but also a way to extract relevant information and discard eventually the ones which are useless, dirty or wrong.
In this scenario, data scientists usually have to process large data samples with hundreds or thousands of variables that \cite{garcia2016big} cannot be directly used by humans or software applications.
This challenge implies that preprocessing steps must be taken such as collecting, cleaning, and transforming to learn from vast datasets.
For example, in the last years, exponential growth of spatial data occurred thanks to devices and instrumentation such as satellite platforms and ground sensor stations. 
One usage is to address them towards sustainable development activities through models and tools in order to improve our environment. Indeed, Big Data is having a crucial relevance in reaching the target of United Nations’ Sustainable Development Goals \cite{zhang2019orchestrating}.
One critical phenomenon that puts risks on the 'Good health and well-being' and 'Climate action' goals is air pollution.
Indeed, air pollution is nowadays considered the world's largest environmental health risk.\\
Science demonstrated that deterioration of ambient air quality, due to the growing concentration of pollutants in the atmosphere, has caused a significant increment of deaths in the world.\par  
Pollutants such as particulate matter, ozone, carbon monoxide and ammonia cause respiratory diseases and are important sources of mortality.
Almost the entire global population (99\%) breathes air that exceeds WHO air quality limits and threatens their health.\newline
In Europe, the air is becoming cleaner, but persistent pollution, especially in cities, is damaging the health of people. One of the last reports, based on the European Environment Agency (EEA), shows that exposure to air pollution caused around 500,000 early deaths in the European Union (EU) in 2018 \cite{european2018air}.\par
One of the most harmful pollutants is \gls{pm}, which can penetrate your lungs or even your bloodstream.\newline 
Particle pollution includes PM10 and PM.25, with less than, respectively, 2.5 and 10 micrometers diameters.
Most particles come from other contaminants such as sulphur dioxide and nitrogen oxides, which are pollutants emitted from power plants, industries and automobiles.\par
However, a significant source of PM is one generated by intensive farming \cite{burkart2007diffuse}.
In particular, this is a relevant issue in the Po Valley, where intensive agricultural activity is highly employed.\par
In this context, human civilization is trying to limit pollution and improve the environment with the use of technology.\newline
Technology is helping to clean up air pollution, with data-based solutions helping make our cities healthier places to live.\newline
Monitoring, analyzing and predicting air quality in urban areas is one of the tools to cope with the climate change problem.\par
The advent of modern Artificial Intelligence (AI) techniques such as \gls{ml} can be considered as new possibilities for researchers to find solutions to various problems affecting air quality and climate change.
\bigskip
Data have to be coded so that they may be easily parsed by the machine. 
Indeed, data in the real world is often dirty with inconsistencies, noise, and missing values since are aggregated from different sources. So it's important to improve the data quality by removing redundant and wrong pieces of data.
In addition to data cleaning, it is essential that the data used for the training in \acrshort{ml} models are appropriate, by discarding eventual confounding or improper data.
A feature selection is required for this purpose, since helps to choose the most considerable variables.
My work is focused in detail on this last step, in which I also tried to interpret, by seeing the results, how each factor affects the target variable, which in my case of study describes pollution phenomena related to agriculture.
The following case of study is part of the D-DUST project which aims to detect factors that contribute more to agricultural pollution (PM2.5 and ammonia) with also a reasonable explanation from the literature.
The \gls{d-dust}, funded by Fondazione Cariplo’s ‘Data Science for Science and Society’ call for proposals, counts on Politecnico di Milano, \gls{dica} as the lead partner.\newline
D-DUST aims to provide information on the impact of agricultural and livestock activities on pollutants in the Po Valley (North Italy).\par 
To reach the goal, data from ground sensors are combined with contributions provided by satellite platforms and, using data science techniques such as machine learning and geostatistical models, provide meaningful information related to the contribution of intensive farming on pollution.\par
The last target of the project is to provide data-driven best-practices to policymakers, farming operators and citizens in order to minimize the production processes' effects on air quality.
\bigskip
In this thesis, we propose an ensemble approach applied in this case of study by means of the selection of the most remarkable covariates that impact pollutants such as PM2.5 and NH3. 
The final step is to build a prediction model in order to evaluate its performance.  
In the next chapter of my report, I will show the tools developed and the strategy chosen to reach this goal. 
This is the content of the next chapters:

\begin{itemize}
  \item \autoref{chap:background} (\textbf{Background and state of art}): it describes the scenario in which my thesis work takes place, referring in particular to the state of the art;
  \item \autoref{chap:Overview} (\textbf{Overview}): it shows the main steps I take in my work;
  \item \autoref{chap:case} (\textbf{Case of Study and Data Modelling}): it's focused on the case of study by explaining each step taken in detail, for both the feature selection and modelling part;
 \item \autoref{chap:res} (\textbf{Interpretation of the results}): it's focused on the results achieved in the case of study (both feature selection and models);
 \item \autoref{chap:conclusion} (\textbf{Conclusions}): it summarises the findings through the results obtained and aims to display future opportunities.  
\end{itemize}

