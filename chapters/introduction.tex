Today, we have to deal with new technologies such as the internet, GPS or satellite platforms, which provide us numerous and large samples of data.\\ 
The data growth in the last decades implies a demand for not only a better collection and storage of data but also a way to extract relevant information and discard eventually the ones which are useless, dirty or wrong.\par
In this scenario, a set of techniques of preprocessing such as data cleaning and transforming is required in order to extract knowledge from vast datasets \cite{garcia2016big}.
\par
For example, in the last years, exponential growth of spatial data occurred thanks to devices and instrumentation such as satellite platforms and ground sensor stations. \\
One usage is to address them towards sustainable development activities through models and tools in order to improve our environment. \\
Indeed, Big Data is having a crucial relevance in reaching the target of United Nations’ Sustainable Development Goals  \cite{zhang2019orchestrating}.
One critical phenomenon that puts risks on the 'Good health and well-being' and 'Climate action' goals is air pollution.\\
Indeed, air pollution is nowadays considered one of the world's largest environmental health risk \cite{fuller2022pollution}.\\
Science demonstrated that deterioration of ambient air quality, due to the growing concentration of pollutants in the atmosphere, has caused a significant increment of deaths in the world.\par  
Pollutants such as particulate matter, ozone, carbon monoxide and ammonia cause respiratory diseases and are important sources of mortality.
Almost the entire global population (99\%) breathes air that exceeds WHO air quality limits and threatens their health \cite{WHOreport}.\newline
In Europe, the air is becoming cleaner, but persistent pollution, especially in cities, is damaging the health of people. One of the last reports, based on the European Environment Agency (EEA), shows that exposure to air pollution caused around 500,000 early deaths in the European Union (EU) in 2018  \cite{european2018air}.\par
One of the most harmful pollutants is \gls{pm}, which can penetrate your lungs or even your bloodstream.\newline 
Particle pollution includes PM10 and PM.25, with less than, respectively, 2.5 and 10 micrometers diameters.
Most particles come from other contaminants such as sulphur dioxide and nitrogen oxides, which are pollutants emitted from power plants, industries and automobiles.\par
However, a significant source of PM is one generated by intensive farming \cite{burkart2007diffuse}.
In particular, this is a relevant issue in the Po Valley, where intensive agricultural activity is highly employed.\\
In this context, human civilization is trying to limit pollution and improve the environment with the use of technology.\newline
Technology is helping to clean up air pollution, with data-based solutions helping make our cities healthier places to live.\newline
Monitoring, analyzing and predicting air quality in urban areas is one of the tools to cope with the climate change problem.\par
The advent of modern Artificial Intelligence (AI) techniques such as \gls{ml} can be considered as new possibilities for researchers to find solutions to various problems affecting air quality and climate change.
\\  
Data have to be coded so that they may be easily parsed by the machine. 
Indeed, data in the real world is often dirty with inconsistencies, noise, and missing values since are aggregated from different sources. So it's important to improve the data quality by removing redundant and wrong pieces of data.\\
In addition to data cleaning, it is essential that the data used for the training in \acrshort{ml} models are appropriate, by discarding eventual confounding or improper data.\\
A feature selection is required for this purpose, since helps to choose the most considerable variables.\par
My work is focused in detail on this last step, in which I also tried to interpret, by seeing the results, how each factor affects the target variable, which in my case study describes pollution phenomena related to agriculture.\\
The following case study is part of the \gls{d-dust} project which aims to detect factors that contribute more to agricultural pollution (PM2.5 and ammonia) with also a reasonable explanation from the literature.\\
The D-DUST project, funded by Fondazione Cariplo’s ‘Data Science for Science and Society’ call for proposals, counts on Politecnico di Milano, \gls{dica} as the lead partner.\newline
D-DUST aims to provide information on the impact of agricultural and livestock activities on pollutants in the Po Valley (North Italy).\\
Data from ground sensors are combined with observations provided by satellite platforms and, using data science techniques such as machine learning and geostatistical models, support the monitoring of farming-related PM.\\
Indeed, D-DUST aims to verify the impact of this integration for PM monitoring and prediction. 
The merge of data from these two different sources could help the implementation of more accurate predictive models, thanks to the sampling accuracy of the ground sensors and the granularity of the satellite observations.\\
Combination of traditional measurements from ground sensors with the satellites observations is considered nowadays a new monitoring approach \cite{de2018modelling}.\\
The last target of the project is to provide data-driven best-practices to policymakers, farming operators and citizens in order to minimize the production processes' effects on air quality.\par
In this thesis, the approach applied to this case study by means of the selection of the most remarkable covariates that impact pollutants (such as PM2.5 and NH3) will contribute in D-DUST for modelling phase.\\
In the next chapter of my report, I will show the tools developed and the strategy chosen to reach this goal. 
This is the content of the next chapters:

\begin{itemize}
  \item \autoref{chap:background} (\textbf{Background and state of art}): it describes the scenario in which my thesis work takes place, referring in particular to the state of the art;
  \item \autoref{chap:Overview} (\textbf{Overview}): it shows the main steps I take in my work;
  \item \autoref{chap:case} (\textbf{Case Study and Data Modelling}): it's focused on the case study by explaining each step taken in detail, for both the feature selection and modelling part;
 \item \autoref{chap:res} (\textbf{Interpretation of the results}): it's focused on the results achieved in the case study (both feature selection and models);
 \item \autoref{chap:conclusion} (\textbf{Conclusions}): it summarises the findings through the results obtained and aims to display future opportunities.  
\end{itemize}