In this chapter I'm going to contextualize the state of the art of my research work. 
Besides, I'll give explanation about the target to reach and the solution applied.\par
The goal of my research is to implement a Machine Learning model capable of predicting pollutant locally with better precision than global scale. 
Data must be preprocessed before training, in order to reduce overfitting and improve accuracy of the final model.
Another aspect to take in consideration is that a ML model trained with so many features it would be a black box, in which a lack of interpretability couldn't be able to explain the decisions taken by the AI.
So it's needed to care about interpretability in order to discard eventually confoundant variables  which can suggest there is a correlation when in fact there is not, even if the model's accuracy is extremely high. 
For instance, a new paper by Alex DeGrave et al.\cite{degrave2021ai} shows that Deep Learning model trained with improper data was taking shortcuts in COVID-19 detection on radiographs because of position of certain markers rather than on the actual radiograph.
Therefore, the key to increase interpretability of a given model is to wonder if given factor should drive the final decision.\par
In this context, in which the black-box nature of ML algorithms raises ethical and judicial concerns inducing lack of trust, Explainable Artificial Intelligence aims to create a model fully interpretable.
Explainable Artificial Intelligence (or Explainable Machine Learning) helps to understand how ML algorithms make prediction, with the usage of Feature Selection methods for determining how well each feature can predict the target variable.
Indeed, before developing a predictive model, feature selection is essential for reducing the number of input variable. 
It is desirable to both reduce the computational cost of modeling and, in some cases, to improve the performance of the model.
In addition, inside the D-DUST project this step aims to provided a weighted score of each environmental variable with respect to the pollutants emitted by intense agricultural.
Nowadays, with the large amount of volume and variety in Big Data, FS is becoming increasingly an essential preprocessing step in machine learning algorithms \cite{kamolov2021feature}.
\par
In litherature we can find various feature selection methods which are classified in three main categories\cite{stanczyk2015feature}:
\subsubsection{Filter Methods}
Filter-based feature selection methods adopt statistical measures to evaluate the correlation/dependence between input variables.
These select features from the without machine learning algorithm. In terms of computation, they are very fast and are very suitable in order to remove duplicated, correlated, redundant variables. On the contrary, these methods do not remove multicollinearity
\subsubsection{Wrapper Methods}
Wrapper methods, as the name suggests, wrap a machine learning model, with different subsets of input features. In this way the subsets are evaluated following the best model performance.
One disadvantage of this approach is the computational costs.
Their exection for many subsets of variables can become unfeasible. 
\subsubsection{Embedded Methods}
Embedded methods instead are characterised by the benefits of both the wrapper and filter methods, by including interactions of features but also having a reasonable computational cost.\par
\bigskip
Due to the fact there isnâ€™t a best feature selection technique, I performed and combined different supervised methods. 
According to the above, my work comes on this scenario, having the aim to preprocessed geospatial data in order to highlight the most weighted input variable that affect the pollutants as target variable.
In the next chapter of my report details I'll show the tools developed and the strategy choosen to reach the target. 
This is the content of the next chapters:

\begin{itemize}
  \item \autoref{chap:Overview} (\textbf{Overview}): It shows the main steps I take in my work;
  \item \autoref{chap:pre} (\textbf{Data Collection and Pre-Processing}): It outlines in detail how data are collected and preprocessed, with particular attention to the feature selection;
  \item \autoref{chap:case} (\textbf{Case of Study and Data Modelling}): It's focused on the results achieved in the case of study (both feature selection and models built);
\end{itemize}
\begin{comment}
Indeed, in recent years ensemble feature selection are being implemented by researchers  
approaches are being developed by researchers. They follow a similar recipe with the well-established ensemble on classification algorithms, which provides better results and robustness than employing single algorithms
\end{comment}



