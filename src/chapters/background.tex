In this chapter I'm going to contextualize the state of the art of my research work. 
Besides, I'll give explanation about the target to reach and the solution applied.\par
The goal of my research is to implement a Machine Learning model capable of predicting pollutant locally with better precision than global scale. 
Data must be pre-processed before training, in order to reduce overfitting and improve accuracy of the final model.\newline
Another aspect to take in consideration is that a ML model trained with so many features it would be a black box, in which a lack of interpretability couldn't be able to explain the decisions taken by the AI.
So it's needed to care about interpretability in order to discard eventually confounding variables  which can suggest there is a correlation when in fact there is not, even if the model's accuracy is extremely high. \newline
For instance, a new paper by Alex DeGrave et al.\cite{degrave2021ai} shows that Deep Learning model trained with improper data was taking shortcuts in COVID-19 detection on radiographs because of position of certain markers rather than on the actual radiograph.
Therefore, the key to increase interpretability of a given model is to wonder if given factor should drive the final decision.\par
In this context, in which the black-box nature of ML algorithms raises ethical and judicial concerns inducing lack of trust\cite{9141213}, Explainable Artificial Intelligence aims to create a model fully interpretable.
Explainable Artificial Intelligence (or Explainable Machine Learning) helps to understand how ML algorithms make prediction, with the usage of Feature Selection methods for determining how well each feature can predict the target variable.
It is desirable to both reduce the computational cost of modelling and, in some cases, to improve the performance of the model.\newline
In order to do that, before developing a predictive model, feature selection is a needed step for reducing the number of input variable. \newline
Nowadays, with the large amount of volume and variety in Big Data, FS is becoming increasingly an essential pre-processing step in machine learning algorithms \cite{kamolov2021feature}.
Inside the D-DUST project this step aims to provided a weighted score of each environmental variable with respect to the pollutants emitted by intense agricultural through regression predictive modeling.\newline
\par
\bigskip
Due to the fact there isnâ€™t a best feature selection technique, I performed and combined different supervised methods. \newline
According to the above, my work comes on this scenario, having the aim to pre-process geospatial data in order to highlight the most weighted input variable that affect the pollutants as target variable.\newline
In the next chapter of my report details I'll show the tools developed and the strategy chosen to reach this goal. 
This is the content of the next chapters:

\begin{itemize}
  \item \autoref{chap:Overview} (\textbf{Overview}): It shows the main steps I take in my work;
  \item \autoref{chap:pre} (\textbf{Data Collection and Pre-Processing}): It outlines in detail how data are collected and pre-processed, with particular attention to the feature selection;
  \item \autoref{chap:case} (\textbf{Case of Study and Data Modelling}): It's focused on the results achieved in the case of study (both feature selection and models built);
\end{itemize}
\begin{comment}
Indeed, in recent years ensemble feature selection are being implemented by researchers  
approaches are being developed by researchers. They follow a similar recipe with the well-established ensemble on classification algorithms, which provides better results and robustness than employing single algorithms
\end{comment}



