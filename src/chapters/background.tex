In this chapter I'm going to contextualize the state of the art of my research work. 
Besides, I'll give explanation about the target to reach and the solution applied.\par
The goal of my research is to implement a Machine Learning model capable of predicting pollutant locally with better precision than global scale. 
Data must be pre-processed before training, in order to reduce overfitting and improve accuracy of the final model.\newline
Another aspect to take in consideration is that a ML model trained with so many features it would be a black box, in which a lack of interpretability couldn't be able to explain the decisions taken by the AI.
So it's needed to care about interpretability in order to discard eventually confounding variables  which can suggest there is a correlation when in fact there is not, even if the model's accuracy is extremely high. \newline
For instance, a new paper by Alex DeGrave et al.\cite{degrave2021ai} shows that Deep Learning model trained with improper data was taking shortcuts in COVID-19 detection on radiographs because of position of certain markers rather than on the actual radiograph.
Therefore, the key to increase interpretability of a given model is to wonder if given factor should drive the final decision.\par
In this context, in which the black-box nature of ML algorithms raises ethical and judicial concerns inducing lack of trust\cite{9141213}, Explainable Artificial Intelligence aims to create a model fully interpretable.
Before the advent of XAI, scientific community was focused on the predictive power of algorithms rather than the understanding behind these predictions.
This need for trustworthy for high performing models led to  eXplainable Artificial Intelligence (XAI), a field focused on the interpretation of how AI systems take decision.
Explainable Artificial Intelligence (or Explainable Machine Learning) helps to understand how ML algorithms make prediction, with the usage of Feature Selection methods for clarify model’s decision.
Feature selection can give relevant explanations by quantifying the influence of each independent variable with a score.
In order to do that, before developing a predictive model, feature selection is a needed step for reducing the number of input variable. \newline
Nowadays, with the large amount of volume and variety in Big Data, FS is becoming increasingly an essential pre-processing step in machine learning algorithms \cite{kamolov2021feature}.
It is desirable to both reduce the computational cost of modelling and, in some cases, to improve the performance of the model.\newline
Inside the D-DUST project this step aims to provided a weighted score of each environmental variable with respect to the pollutants emitted by intense agricultural through regression predictive modeling.\newline
\par
Due to the fact there isn’t a best feature selection technique, I performed and combined different supervised methods. 
\bigbreak
According to the above, my work comes on this scenario, having the aim to pre-process geospatial data in order to highlight the most weighted input variable that affect the pollutants related to intense agriculture and farming.\newline




