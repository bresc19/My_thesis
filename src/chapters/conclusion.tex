The aim of this chapters is to highlight the main aspect turned out in my work.
Based on the results achieved in the previous chapter, we can conclude that Machine Learning models performed differently for many factor such as the type of model, configuration and resolution.
In the test run before, it's possible to realize the factor that make a result more accurate than others.\\
An important aspect shown in my work is the importance of the number of observations used from training data. In order to have enhanced estimation, the increment of these is essential.\\
In ML models performance grows up as the model complexity, turning such systems into “black box” approaches and implying uncertainty in the way they work and come to decisions. 
This become a problematic challenge for machine learning systems to be used in critical domains, such as healthcare or economic aspect.
The use of feature selection supports more efficient debugging for causalities and a more trust in the model.
For doing this, feature selection attempt to clarify a model’s decision by determine the influence of each input variable. 
Scores of feature selection alone may not always represent a comprehensive explanation, but it's helpful for understanding the model’s reasoning.\\
Nevertheless, this case of study was not brought to build a proper model for air pollution forecast; instead it aims to detect how the selection of relevant features could affect the model performance. \\
The present study confirmed the findings about the model performance which increases if a feature selection is applied, in particular when we have to deal with limited sample of data\cite{vabalas2019machine}. 
In addition, what coming out from this is that more the training sample size is limited, more an accurate selection of the most weighted variables is needed to increase its performance.
\begin{comment}
In this work so it's highlighted the effect of how the training in ML should benefit from an accurate selection of variable. 
\end{comment}
Instead of faultless building model with exact predictions, the results in this research was pointed more to the fact that model was interpretable from the covariates chosen. 
One of the future outcomes from this is absolutely the importance of a model sufficiently explained.
Future research on AI should extend the explanations and interpretability of ML models.
In high-risk applications, AI shouldn't be in blind. 
It's needed to dissect a model for a proper comprehension and explanation before it produce any outputs, especially with large data set.
For sure models like those could be helpful for the implementation of precise forecast models. Indeed, using this as an important component for making average through an ensemble technique (as it has been already done with the CAMS model) should be one usage.
\\
In summary, this work argued that with using feature selection it's possible to detect which are the main factors affecting the target variable and, possibly, to control them aiming to reduce such as pollutants effects.\\
The score assumed by each different variable in the case of study provide a measure of the influence with respect to ammonia and fine particle formation, with also confirmation in literature.
Looking forward, further attempts for reducing pollutant formation should be made by procedures actually used.

