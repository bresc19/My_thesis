Nowadays, we have to deal with new technologies such as internet, GPS or satellites platform which provide us numerous and large sample of data. The data growth in the last decades implies a demand for not only a better collection and storage of data, but also a way to extract relevant information and discard eventually the ones which are useless, dirty or wrong.
In this scenario data scientist usually have to process large sample of data with hundreds or thousands of variables which \cite{garcia2016big} cannot be directly used by humans or software applications.
This challenge implies that preprocessing steps have to be taken like collecting, cleaning and transforming  in order to learn from vast datasets.
In the last years a exponential growth of spatial data occurred thanks to devices and instrumentation such as satellite platform and ground sensor station. 
An usage is to address them towards sustainable development activities through models and tools in order to improve our environment. Indeed, Big Data is having a crucial relevance for reaching the target by United Nations’ Sustainable Development Goals \cite{zhang2019orchestrating}.
One critical phenomena which takes risk for “Good Health and well-being” and “Climate Action” goals is the air pollution.
Science demonstrated that deterioration of ambient air quality, due to the growing concentration of pollutant in the atmosphere, has caused a significant increment of deaths in the world.\par  
Pollutants such as particulate matter, ozone, carbon monoxide and ammonia cause respiratory diseases, and are important sources of mortality.
Almost the entire global population (99\%) breathes air that exceeds WHO air quality limits, and threatens their health.\newline
In Europe air is getting cleaner, but persistent pollution, especially in cities, is damaging people’s health. One of the last reports which is based on the European Environment Agency’s (EEA), shows that exposure to air pollution caused around 500,000 early deaths in the European Union (EU) in 2018 \cite{european2018air}.\par
One of the most harmful pollutants is the \textbf{particulate matter (PM2.5 or PM10)} which can get deep into your lungs or even get into your bloodstream.\newline
Most of the particles come from chemical reactions such as sulphur dioxide and nitrogen oxides, which are pollutants emitted from power plants, industries and automobiles.\par
However, a significant sources of PM are the chemical reactions generated by intensive farming \cite{burkart2007diffuse}.
In particular this is a relevant issue in the Po Valley, where intensive agricultural activity is very employed.\par
In this context, human civilization is trying to limit pollution and improve environment with use of technology.\newline
Technology is helping to clean up air pollution, with data analytic-based solutions helping to make our cities healthier places to live.\newline
Monitoring, analysing and predicting the air quality in urban areas is one of the effective solutions for coping with the climate change problem.\par
The advent of modern Artificial Intelligence (AI) techniques such as Machine Learning (ML) can be considered as new possibilities for researchers to find solutions to various problems affecting air quality and climate change.
\bigskip
In this work is about the pre processing phase, in which data have to be coded so that it may be easily parsed by the machine. 
Indeed, data in the real world is often dirty with inconsistencies, noise, and missing values since are aggregated from different sources. So it's important to improve the data quality by removing redundant and wrong pieces of data.
As well as the data cleaning, it's essential that data used for the training in ML models should be appropriate, by discarding eventual confounding or improper data.
A feature selection is required for this purpose, since helps to choose the most considerable variables by numerical scores obtained in regression analysis.
My work is focused in details on this last step in which I also tried to understand, by seeing the results, how much each factor can affect the target variable, which in my case of study describes pollution phenomena related to agriculture.
The following case of study takes part in the D-DUST project with the aim to detect factor that contributes more on pollution from farming (PM2.5 and Ammonia) with also reasonable explanation from literature.
The \textbf{D-DUST project} (Data-driven moDelling of particUlate with Satellite Technology aid), funded by Fondazione Cariplo’s ‘Data Science for Science and Society’ call for proposals, counts on Politecnico di Milano, Department of Civil and Environmental Engineering (DICA) as lead partner.\newline
D-DUST aims to provide knowledge about the impact of agricultural and livestock activities on pollutants in the Po Valley (Northern Italy).\par 
For reaching the goal, data from ground sensor are combined with contribution provided by satellite platforms and, with the use of data science techniques like machine-learning and geostatistical models, provide meaningful information related to the contribution of intensive farming on pollution.\par
The last target of the project is to provide a data-driven best-practices to policymakers, farming operators and citizens in order to minimize the production processes' effects on air quality.
\bigskip
In this thesis we propose an ensemble approach for analysing data and provide useful information regarding intense agricultural activity through selection of the most remarkable covariates that impact on PM2.5 and NH3 pollutants. 
The final step is to build a model skilled to estimate pollutant estimation locally, better than global scale model.  
In the next chapter of my report details I'll show the tools developed and the strategy chosen to reach this goal. 
This is the content of the next chapters:

\begin{itemize}
  \item \autoref{chap:background} (\textbf{Background and state of art}): it describes the scenario in which my thesis work takes place, referring in particular to the state of the art;
  \item \autoref{chap:Overview} (\textbf{Overview}): it shows the main steps I take in my work;
  \item \autoref{chap:case} (\textbf{Case of Study and Data Modelling}): it's focused on the case of study by explaining each steps taken in detail, for both the feature selection and modelling part;
 \item \autoref{chap:res} (\textbf{Interpretation of the results}): it's focused on the results achieved in the case of study (both feature selection and models built);
 \item \autoref{chap:conclusion} (\textbf{Conclusions}): it summarises the findings through the results obtained and aims to display future opportunities.  
\end{itemize}

