Science demonstrated that deterioration of ambient air quality, due to the growing concentration of pollutant in the atmosphere, has caused a significant increment of deaths in the world.\par  
Pollutants such as particulate matter, ozone, carbon monoxide and ammonia cause respiratory diseases, and are important sources of mortality.
Almost the entire global population (99\%) breathes air that exceeds WHO air quality limits, and threatens their health.\newline
In Europe air is getting cleaner, but persistent pollution, especially in cities, is damaging people’s health. The latest reports are based on the European Environment Agency’s (EEA), which shows that exposure to air pollution caused around 400,000 early deaths in the European Union (EU) in 2016.\par
One of the most harmful pollutants is the \textbf{particulate matter (PM25 or PM10)} which can get deep into your lungs or even get into your bloodstream.\newline
Most of the particles come from chemical reactions such as sulfur dioxide and nitrogen oxides, which are pollutants emitted from power plants, industries and automobiles.\par
However, a significant sources of PM are the chemical reactions generated by intensive farming.
In particular this is a significant issue in the Po Valley, where intensive agricultural activity is very employed.\par
In this context, human civilization is trying to limit pollution and improve environment with use of technology.\newline
Technology is helping to clean up air pollution, with data analytics-based solutions helping to make our cities healthier places to live.\newline
Monitoring, analysing and predicting the air quality in urban areas is one of the effective solutions for coping with the climate change problem.\newline
The coming of modern Artificial Intelligence (AI) techniques such as Machine Learning (ML) can be considered as new possibilities for researchers to find solutions to various problems affecting air quality and climate change.
\section{D-Dust}
In this context, the \textbf{D-DUST project} (Data-driven moDelling of particUlate with Satellite Technology aid), funded by Fondazione Cariplo’s ‘Data Science for Science and Society’ call for proposals, counts on Politecnico di Milano, Department of Civil and Environmental Engineering (DICA) as lead partner.\newline
D-DUST aims to provide knowledge about the impact of agricultural and livestock activities on pollutants in the Po Valley (Northern Italy).\par 
For reaching the goal, data from ground sensor are combined with contribution provided by satellite platforms and, with the use of data science tecniques like machine-learning and geostatistical models, provide meaningfull information related to the contribution of intensive farming on pollution.
The last target of the project is to provide a data-driven best-practices to policymakers, farming operators and citizens in order to minimize the production processes' effects on air quality.
\section{Overview}
In this context, I give my conribution to the D-DUST project. In this thesis we propose an ensamble approach for analysing data and provide usefull information regarding intense agricoltural activity. \par
\subsection{Preprocessing}
Mainly my work is focused on the first phase of a data analysis procedure which is the preprocessing.
Data preprocessing (or data preparation) is the process of transforming raw data into a format that suitable for modeling. Indeed, raw data is in most cases incomplete and noisy.
Nowadays, dealing with big amount of informations, the probability of incorrect data is higher without a proper data preproccesing. 
Only high-quality data can generate accurate models and predictions. Hence, it’s crucial to process data with the best possible quality before training them with artificial intelligence, and machine learning predictive models.
Its essential steps are these.

\subsubsection{Data Collection}
Relevant data is gathered from their source in data structures (such as Dataframes). In our work, data come from \textit{fixed ground-sensor} and \textit{satellite-based platform} and are enterely numerical.
\subsubsection{Data Cleaning}
It involves fixing problems or errors in messy or incomplete data. There are general data cleaning operation which has to be performed, such as identifyng:
\begin{itemize}
\item duplicate rows of data and remove them;
\item rows with NaN values and remove them;
\item columns that have low variance and drop them;
\end{itemize}
\subsubsection{Data Trasformation}
Data need to be scaled. As a matter of fact, each feature in our data has varying degrees of magnitude, range, and units. This is a issue for machine learning algorithms beacuse of highly sensitive to these features. So in input or output data we performed:
\begin{itemize}
\item Standardization: Scale a feature to a standard Gaussian;
\item Normalization: Scale a feature to the range 0 and 1;
\end{itemize}
\subsubsection{Feature Selection}
Feature Selection is the core part of this study. It's the process of reducing the number of input variables when developing a predictive model. 
Data collected, even if have been cleaned and transformed, are anyway characterized by big amount of variables which are redoundant.
Discarding irrelevant data is essential before applying Machine Learning model in order to:
\begin{itemize}
\item \textbf{Reduce Overfitting}: less opportunity to make decisions based on noise;
\item \textbf{Improve Accuracy}: less misleading data means modelling accuracy improves. Predictions can be greatly distorted by redundant attributes;
\item \textbf{Reduce Training Time}: With less data the algorithms will train faster;
\end{itemize}
In this step, which will be explained in detail in the next chapters, the reduced input variable are the ones that are irrelevant with respect to a target variable as output. \newline
In this study target variables choosen represent the pollution phenomena such as the PM25 and Ammonia emissions. We choose these targets because are the most relevant sources of pollution produced by intensive agricultural.\par
Due to the fact that there isn’t a best feature selection technique, many different methods are performed, each one that give different correlation results.\par
The final results of this step is, for every method, the evaluation of score assigned to each variable related to its contribution on the output.\par
Finally a voting algorithm is perfomed in order to average the scores of each variable and the features with the highest values are selected for model as input.
\section{Model prediction}
Predictive analytics are tecniques that make predictions on the behavior of an output variable. 
For doing prediction, I employ 2 supervised AI models.\newline
\subsection{Neural Network regression with Keras}
\subsection{Machine Learning with Random Forest regressor}